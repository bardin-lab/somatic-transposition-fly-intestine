{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking again at TE frequency relative to causative event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import namedtuple\n",
    "from seaplotlib.helper import despine, save_fig_in_dir\n",
    "\n",
    "gff = namedtuple('GFF', 'chrom source feature start end score strand frame sample_id vaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ALL_INSERTIONS = '0.5.21.filtered_calls_prosgfp_guts.gff'\n",
    "DELETION_READ_RATIO = 'pros_purity_estimates_deletion.tab'\n",
    "LABEL = 'ProsGFP guts'\n",
    "IMAGE_EXTENSION = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_readtagger_confirmed_insertions(path):\n",
    "    entries = []\n",
    "    with open(path) as in_file:\n",
    "        for line in in_file:\n",
    "            fields = line.strip().split('\\t')\n",
    "            attributes = fields[8]\n",
    "            attributes = dict([a.split('=') for a in attributes.split(';')])\n",
    "            fields[8] = attributes['ID'].split('_')[0]\n",
    "            left_count = int(attributes['left_mate_count'])\n",
    "            right_count = int( attributes['right_mate_count'])\n",
    "            ref_count = int(attributes['nref'])\n",
    "            fields.append((left_count + right_count) / (left_count + right_count + ref_count + 0.01))\n",
    "            entries.append(gff(*fields))\n",
    "    df = pd.DataFrame.from_records(entries)\n",
    "    df.columns = list(entries[0]._asdict().keys())\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform_df_for_plotting(df):\n",
    "    \"\"\"Add autosome column, sorts by sample and variant allele frequency.\"\"\"\n",
    "    df['autosome'] = df.chrom.str.len() > 1\n",
    "    autosome_values = df[df['autosome'] == True].vaf * 2\n",
    "    # Multiply VAF for autosomes by 2 and cut values at 1\n",
    "    df.loc[autosome_values.index, 'vaf'] = autosome_values\n",
    "    # df.loc[df['vaf'] > 1, 'vaf'] = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_purity_values(path):\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "    # This is the (normalized) read ratio of control to tumor\n",
    "    # We can get the purity \n",
    "    df['purity'] = (df[0] - 1) / df[0]\n",
    "    df.index = df[1]\n",
    "    return df.purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_readtagger_confirmed_insertions(ALL_INSERTIONS)\n",
    "raw_df = transform_df_for_plotting(df)\n",
    "df = raw_df.copy()\n",
    "df.loc[df['vaf'] > 1, 'vaf'] = 1\n",
    "deletion = read_purity_values(DELETION_READ_RATIO)\n",
    "for i, s_id in enumerate(df['sample_id'].unique()):\n",
    "    if s_id in deletion.index:\n",
    "        df.loc[df['sample_id'] == s_id, 'notch_vaf'] = deletion[s_id]\n",
    "    else:\n",
    "        # Give some very low AF for plotting\n",
    "        df.loc[df['sample_id'] == s_id, 'notch_vaf'] = 0 + (1/ (i+1) *100)\n",
    "# df = df[~df['notch_vaf'].isnull()]\n",
    "# uncomment this to color by TE\n",
    "# df['color'] = df['feature']\n",
    "# df.loc[~df.feature.str.match('rover|I-element|copia'), 'color'] = 'other'\n",
    "df['color'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "ax = sns.boxplot(x=\"sample_id\", y=\"vaf\", hue='autosome', data=df)\n",
    "# sns.swarmplot(x='sample_id', y='vaf', hue='autosome', data=df, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get only X chromosome\n",
    "# df = df[df['chrom'] == 'X']\n",
    "\n",
    "def plot_vaf(*args, **kwargs):\n",
    "    data = kwargs['data']\n",
    "    xmin = data.order.min() - 10\n",
    "    xmax = data.order.max() + 10\n",
    "    y = data.notch_vaf.max()\n",
    "    ax = plt.gca()\n",
    "    ax.hlines(y=y, xmin=xmin, xmax=xmax, color=kwargs['color'], label=kwargs['label'])\n",
    "    \n",
    "    \n",
    "def scatter(x, y, **kwargs):\n",
    "    kwargs.pop('color')\n",
    "    plt.scatter(x, y, color='grey', **kwargs)\n",
    "\n",
    "df = df.sort_values(['notch_vaf', 'vaf'])\n",
    "sample_order = {sample_id: i for i, sample_id in enumerate(df.sample_id.unique())}\n",
    "df['order'] = list(range(len(df)))\n",
    "last_addition = 0\n",
    "for index, group in df.groupby('sample_id').order:\n",
    "    df.loc[group.index, 'order'] = group.values + (sample_order[index] * 20)\n",
    "\n",
    "# g = sns.FacetGrid(df, hue=\"sample_id\", col=\"sample_id\",size=8, col_wrap=6, sharex=False)\n",
    "g = sns.FacetGrid(df, hue=\"color\", aspect=2, height=10)\n",
    "g.map(scatter, \"order\", \"vaf\")\n",
    "# g.map(plt.plot, \"order\", \"vaf\")\n",
    "# fg = g.map(plt.plot, \"order\", \"notch_vaf\")\n",
    "# plt.axvline(-10, color='k', linestyle='--')\n",
    "for sep in df.groupby('sample_id')['order'].max().values:\n",
    "    if not sep == df.order.max():\n",
    "        plt.axvline(sep + 10, color='k', linestyle='--')\n",
    "\n",
    "\n",
    "plot_vaf(data=df.groupby('sample_id'), color='black', label=None)\n",
    "# g.map_dataframe(plot_vaf, 'order', 'notch_vaf')\n",
    "midpoint_order = df.groupby('sample_id').order.mean()\n",
    "g.set(xticks=midpoint_order.values)\n",
    "g.set_xticklabels(midpoint_order.keys())\n",
    "\n",
    "g.set(xlim=(-10, df.order.max() + 10), ylim=(0, 1.01))\n",
    "\n",
    "g.set_axis_labels(y_var='Penetrance (Variant Allele Frequency * 2 on autosomes)')\n",
    "g.set_xlabels(label='')\n",
    "# fg.set_xticklabels(labels='')\n",
    "sns.despine(left=True, bottom=True)\n",
    "# g.add_legend()\n",
    "save_fig_in_dir(g, 'Insertion Penetrance Estimate %s.%s' % (LABEL, IMAGE_EXTENSION), directory=LABEL, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = raw_df.groupby('sample_id')['vaf'].quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_half = raw_df[raw_df.apply(lambda row: quantiles[row['sample_id']] > row['vaf'], axis=1)]\n",
    "lower_half = raw_df[raw_df.apply(lambda row: quantiles[row['sample_id']] < row['vaf'], axis=1)]\n",
    "frequency_higher_than_notch = df[df.apply(lambda row: row['vaf'] > row['notch_vaf'], axis=1)]\n",
    "frequency_lower_than_notch = df[df.apply(lambda row: row['vaf'] < row['notch_vaf'], axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upper_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lower_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency_higher_than_notch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency_lower_than_notch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tsv(df, path):\n",
    "    df.to_csv(os.path.join(LABEL, path), sep='\\t', index=None)\n",
    "\n",
    "df_path = [\n",
    "    (upper_half, 'upper_half_insertions.tsv'),\n",
    "    (lower_half, 'lower_half_insertions.tsv'),\n",
    "    (frequency_higher_than_notch, 'frequency_higher_than_notch.tsv'),\n",
    "    (frequency_lower_than_notch, 'frequency_lower_than_notch.tsv'),\n",
    "]\n",
    "\n",
    "for df, path in df_path:\n",
    "    to_tsv(df, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
